{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNamLK5cCeST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import string\n",
        "from pickle import load\n",
        "from numpy import array\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG6AYIryZfgm",
        "colab_type": "code",
        "outputId": "de2a9503-fb87-48db-a0cf-d594f5a25af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_path = \"hin.txt\"\n",
        "lines = io.open(data_path, encoding = \"utf-8\").read().split(\"\\n\")\n",
        "lines  = lines[:-1]\n",
        "lines = [line.split(\"\\t\") for line in lines]\n",
        "print(lines[100])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I have a dog.', 'मेरे पास एक कुत्ता है।']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hFXLZCyn_i3q",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def clean_pairs(lines):\n",
        "    cleaned = list()\n",
        "    for pair in lines:\n",
        "        clean_pair = list()\n",
        "        for line in pair:\n",
        "            line.split()\n",
        "            line = [word.lower() for word in line]\n",
        "            clean_pair.append(''.join(line))\n",
        "        cleaned.append(clean_pair)\n",
        "    return np.array(cleaned)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqGNXzK7DAXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = clean_pairs(lines)\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "l = [[w[0].translate(table), w[1].translate(table)] for w in l]\n",
        "l = np.array(l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM5WLO5pZxhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer\n",
        "\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)\n",
        "\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X\n",
        "\n",
        "def encode_output(sequences, vocab_size):\n",
        "\tylist = list()\n",
        "\tfor sequence in sequences:\n",
        "\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n",
        "\t\tylist.append(encoded)\n",
        "\ty = array(ylist)\n",
        "\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
        "\treturn y\n",
        "\n",
        "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
        "\tmodel.add(LSTM(n_units))\n",
        "\tmodel.add(RepeatVector(tar_timesteps))\n",
        "\tmodel.add(LSTM(n_units, return_sequences=True))\n",
        "\tmodel.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7f1a16b3-2cc5-48d8-c0fe-7463ea871745",
        "id": "5TD4aLl0_jna",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = []\n",
        "for i in l[:,0]:\n",
        "    for j in i.split():\n",
        "        if j not in x:\n",
        "            x.append(j)\n",
        "print(len(x))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLGP3ZPma6NN",
        "colab_type": "code",
        "outputId": "0231a1b7-51d6-4d3f-af5f-0e424f523729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(l[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(l[:, 0])\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "print('English Max Length: %d' % (eng_length))\n",
        "# prepare german tokenizer\n",
        "hindi_tokenizer = create_tokenizer(l[:, 1])\n",
        "hindi_vocab_size = len(hindi_tokenizer.word_index) + 1\n",
        "hindi_length = max_length(l[:, 1])\n",
        "print('Hindi Vocabulary Size: %d' % hindi_vocab_size)\n",
        "print('Hindi Max Length: %d' % (hindi_length))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 2398\n",
            "English Max Length: 22\n",
            "Hindi Vocabulary Size: 3030\n",
            "Hindi Max Length: 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqnG3R7w-OqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_length = 2500\n",
        "trainX = encode_sequences(eng_tokenizer, eng_length, l[:train_length][:, 0])\n",
        "trainY = encode_sequences(hindi_tokenizer, hindi_length, l[:train_length][:, 1])\n",
        "trainY = encode_output(trainY, hindi_vocab_size)\n",
        "# prepare validation data\n",
        "testX = encode_sequences(eng_tokenizer, eng_length, l[train_length:][:, 0])\n",
        "testY = encode_sequences(hindi_tokenizer, hindi_length, l[train_length:][:, 1])\n",
        "testY = encode_output(testY, hindi_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vw0MsaNDN26",
        "colab_type": "code",
        "outputId": "5c7a4e05-5cad-48de-a265-59bf53cd0e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2500, 22)\n",
            "(2500, 25, 3030)\n",
            "(369, 22)\n",
            "(369, 25, 3030)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWJ_YBiXAbLW",
        "colab_type": "code",
        "outputId": "1e0f6736-9442-48e6-83a0-e2e596cd88d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(trainX[110])\n",
        "print(l[110])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[25  5 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "['what is this' 'यह क्या है']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxl7257qA9Y0",
        "colab_type": "code",
        "outputId": "97c41656-8f10-4860-c799-4fd312b3a74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(trainY.shape)\n",
        "index=5\n",
        "print(trainY[100][index])\n",
        "for i,x in enumerate(trainY[100][index]):\n",
        "    if(x==1):\n",
        "        print(i,end=\" \")\n",
        "print(l[100])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2500, 25, 3030)\n",
            "[1. 0. 0. ... 0. 0. 0.]\n",
            "0 ['i have a dog' 'मेरे पास एक कुत्ता है।']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALurulKHDZGE",
        "colab_type": "code",
        "outputId": "42d87f5b-bd09-4e6b-a3e4-f2e412ece3f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# define model\n",
        "model = define_model(eng_vocab_size, hindi_vocab_size, eng_length, hindi_length, 256)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "print(model.summary())\n",
        "plot_model(model, to_file='model.png', show_shapes=True)\n",
        "model.fit(trainX, trainY, epochs=200, validation_data=(testX, testY))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 22, 256)           613888    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 25, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 25, 256)           525312    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 25, 3030)          778710    \n",
            "=================================================================\n",
            "Total params: 2,443,222\n",
            "Trainable params: 2,443,222\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 2500 samples, validate on 369 samples\n",
            "Epoch 1/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 2.8724 - val_loss: 3.3275\n",
            "Epoch 2/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.7857 - val_loss: 3.3283\n",
            "Epoch 3/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.7634 - val_loss: 3.1686\n",
            "Epoch 4/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.6955 - val_loss: 3.2876\n",
            "Epoch 5/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.6160 - val_loss: 3.2215\n",
            "Epoch 6/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.5672 - val_loss: 3.2312\n",
            "Epoch 7/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.5335 - val_loss: 3.1623\n",
            "Epoch 8/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.5182 - val_loss: 3.2175\n",
            "Epoch 9/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.4964 - val_loss: 3.2414\n",
            "Epoch 10/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.5085 - val_loss: 3.2799\n",
            "Epoch 11/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.4766 - val_loss: 3.3737\n",
            "Epoch 12/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.4684 - val_loss: 3.2329\n",
            "Epoch 13/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.4526 - val_loss: 3.2846\n",
            "Epoch 14/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.4383 - val_loss: 3.3679\n",
            "Epoch 15/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.4186 - val_loss: 3.3106\n",
            "Epoch 16/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.4068 - val_loss: 3.3373\n",
            "Epoch 17/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.3952 - val_loss: 3.3644\n",
            "Epoch 18/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 1.3808 - val_loss: 3.4230\n",
            "Epoch 19/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.3693 - val_loss: 3.5229\n",
            "Epoch 20/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.3562 - val_loss: 3.4794\n",
            "Epoch 21/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 1.3417 - val_loss: 3.5705\n",
            "Epoch 22/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.3398 - val_loss: 3.5043\n",
            "Epoch 23/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.3201 - val_loss: 3.5177\n",
            "Epoch 24/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.3019 - val_loss: 3.5079\n",
            "Epoch 25/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.2901 - val_loss: 3.5326\n",
            "Epoch 26/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.2786 - val_loss: 3.5519\n",
            "Epoch 27/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.2614 - val_loss: 3.5450\n",
            "Epoch 28/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.2502 - val_loss: 3.5790\n",
            "Epoch 29/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.2430 - val_loss: 3.6498\n",
            "Epoch 30/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.2265 - val_loss: 3.6331\n",
            "Epoch 31/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.2154 - val_loss: 3.5185\n",
            "Epoch 32/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 1.2052 - val_loss: 3.6087\n",
            "Epoch 33/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 1.2204 - val_loss: 3.6453\n",
            "Epoch 34/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.1915 - val_loss: 3.6536\n",
            "Epoch 35/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.1785 - val_loss: 3.7343\n",
            "Epoch 36/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 1.1694 - val_loss: 3.6758\n",
            "Epoch 37/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.1403 - val_loss: 3.6429\n",
            "Epoch 38/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.1288 - val_loss: 3.6277\n",
            "Epoch 39/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.1122 - val_loss: 3.7478\n",
            "Epoch 40/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 1.0993 - val_loss: 3.7096\n",
            "Epoch 41/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.0835 - val_loss: 3.7001\n",
            "Epoch 42/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.0662 - val_loss: 3.7251\n",
            "Epoch 43/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.0521 - val_loss: 3.7087\n",
            "Epoch 44/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.0385 - val_loss: 3.7649\n",
            "Epoch 45/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.0257 - val_loss: 3.7589\n",
            "Epoch 46/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.0127 - val_loss: 3.7782\n",
            "Epoch 47/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 1.0053 - val_loss: 3.7882\n",
            "Epoch 48/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.9869 - val_loss: 3.7697\n",
            "Epoch 49/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.9731 - val_loss: 3.7960\n",
            "Epoch 50/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.9555 - val_loss: 3.8488\n",
            "Epoch 51/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.9385 - val_loss: 3.8178\n",
            "Epoch 52/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.9231 - val_loss: 3.8467\n",
            "Epoch 53/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.9094 - val_loss: 3.9267\n",
            "Epoch 54/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.8920 - val_loss: 3.8715\n",
            "Epoch 55/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.8755 - val_loss: 3.8697\n",
            "Epoch 56/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.8602 - val_loss: 3.8607\n",
            "Epoch 57/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.8390 - val_loss: 3.9277\n",
            "Epoch 58/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.8295 - val_loss: 3.9799\n",
            "Epoch 59/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.8145 - val_loss: 3.9311\n",
            "Epoch 60/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.7955 - val_loss: 3.9075\n",
            "Epoch 61/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.7737 - val_loss: 3.9424\n",
            "Epoch 62/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.7622 - val_loss: 3.9166\n",
            "Epoch 63/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.7490 - val_loss: 3.9293\n",
            "Epoch 64/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.7358 - val_loss: 3.9424\n",
            "Epoch 65/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.7192 - val_loss: 3.9191\n",
            "Epoch 66/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.7066 - val_loss: 3.9912\n",
            "Epoch 67/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.6879 - val_loss: 3.9595\n",
            "Epoch 68/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.6736 - val_loss: 4.0740\n",
            "Epoch 69/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.6542 - val_loss: 4.0123\n",
            "Epoch 70/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.6417 - val_loss: 4.0039\n",
            "Epoch 71/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.6378 - val_loss: 4.0036\n",
            "Epoch 72/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.6482 - val_loss: 4.0023\n",
            "Epoch 73/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.6278 - val_loss: 3.9942\n",
            "Epoch 74/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.6049 - val_loss: 4.0468\n",
            "Epoch 75/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.5804 - val_loss: 4.0268\n",
            "Epoch 76/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.5610 - val_loss: 4.0568\n",
            "Epoch 77/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.5480 - val_loss: 4.1094\n",
            "Epoch 78/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.5362 - val_loss: 4.0971\n",
            "Epoch 79/200\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.5245 - val_loss: 4.1059\n",
            "Epoch 80/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.5097 - val_loss: 4.1164\n",
            "Epoch 81/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.4973 - val_loss: 4.1518\n",
            "Epoch 82/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.4877 - val_loss: 4.1084\n",
            "Epoch 83/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.4810 - val_loss: 4.1151\n",
            "Epoch 84/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.4664 - val_loss: 4.1544\n",
            "Epoch 85/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.4566 - val_loss: 4.0838\n",
            "Epoch 86/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.4711 - val_loss: 4.1605\n",
            "Epoch 87/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.4486 - val_loss: 4.2119\n",
            "Epoch 88/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.4361 - val_loss: 4.1885\n",
            "Epoch 89/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.4124 - val_loss: 4.2241\n",
            "Epoch 90/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.3975 - val_loss: 4.1992\n",
            "Epoch 91/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.3852 - val_loss: 4.1867\n",
            "Epoch 92/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.3791 - val_loss: 4.2380\n",
            "Epoch 93/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.3731 - val_loss: 4.2527\n",
            "Epoch 94/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.3649 - val_loss: 4.2517\n",
            "Epoch 95/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.3568 - val_loss: 4.1961\n",
            "Epoch 96/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.3533 - val_loss: 4.2628\n",
            "Epoch 97/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.3729 - val_loss: 4.2561\n",
            "Epoch 98/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.3666 - val_loss: 4.2912\n",
            "Epoch 99/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.3444 - val_loss: 4.3253\n",
            "Epoch 100/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.3264 - val_loss: 4.2834\n",
            "Epoch 101/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.3116 - val_loss: 4.2782\n",
            "Epoch 102/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2989 - val_loss: 4.3249\n",
            "Epoch 103/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2926 - val_loss: 4.3134\n",
            "Epoch 104/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2871 - val_loss: 4.3358\n",
            "Epoch 105/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2767 - val_loss: 4.3449\n",
            "Epoch 106/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2727 - val_loss: 4.3365\n",
            "Epoch 107/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.2678 - val_loss: 4.3681\n",
            "Epoch 108/200\n",
            "2500/2500 [==============================] - 36s 14ms/step - loss: 0.2594 - val_loss: 4.3619\n",
            "Epoch 109/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2530 - val_loss: 4.3178\n",
            "Epoch 110/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2683 - val_loss: 4.4054\n",
            "Epoch 111/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2528 - val_loss: 4.4032\n",
            "Epoch 112/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2423 - val_loss: 4.4240\n",
            "Epoch 113/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2288 - val_loss: 4.4354\n",
            "Epoch 114/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2161 - val_loss: 4.4104\n",
            "Epoch 115/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2073 - val_loss: 4.4228\n",
            "Epoch 116/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2011 - val_loss: 4.4586\n",
            "Epoch 117/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1951 - val_loss: 4.4530\n",
            "Epoch 118/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1892 - val_loss: 4.4896\n",
            "Epoch 119/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1836 - val_loss: 4.4828\n",
            "Epoch 120/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1799 - val_loss: 4.5125\n",
            "Epoch 121/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.1788 - val_loss: 4.4854\n",
            "Epoch 122/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.1939 - val_loss: 4.4956\n",
            "Epoch 123/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.1894 - val_loss: 4.4819\n",
            "Epoch 124/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.1786 - val_loss: 4.5078\n",
            "Epoch 125/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.1707 - val_loss: 4.5252\n",
            "Epoch 126/200\n",
            "2500/2500 [==============================] - 38s 15ms/step - loss: 0.1652 - val_loss: 4.5453\n",
            "Epoch 127/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.1564 - val_loss: 4.5785\n",
            "Epoch 128/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1462 - val_loss: 4.5536\n",
            "Epoch 129/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.1372 - val_loss: 4.5501\n",
            "Epoch 130/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.1299 - val_loss: 4.5902\n",
            "Epoch 131/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.1247 - val_loss: 4.5808\n",
            "Epoch 132/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1207 - val_loss: 4.6121\n",
            "Epoch 133/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1182 - val_loss: 4.6222\n",
            "Epoch 134/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1154 - val_loss: 4.6200\n",
            "Epoch 135/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1174 - val_loss: 4.6215\n",
            "Epoch 136/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1280 - val_loss: 4.6507\n",
            "Epoch 137/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1382 - val_loss: 4.5985\n",
            "Epoch 138/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1573 - val_loss: 4.5931\n",
            "Epoch 139/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1524 - val_loss: 4.6378\n",
            "Epoch 140/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1267 - val_loss: 4.6807\n",
            "Epoch 141/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1059 - val_loss: 4.6759\n",
            "Epoch 142/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0934 - val_loss: 4.6840\n",
            "Epoch 143/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0863 - val_loss: 4.6858\n",
            "Epoch 144/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0835 - val_loss: 4.7007\n",
            "Epoch 145/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.0802 - val_loss: 4.7009\n",
            "Epoch 146/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.0786 - val_loss: 4.7146\n",
            "Epoch 147/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.0749 - val_loss: 4.7339\n",
            "Epoch 148/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0724 - val_loss: 4.7132\n",
            "Epoch 149/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0730 - val_loss: 4.7400\n",
            "Epoch 150/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.0792 - val_loss: 4.7572\n",
            "Epoch 151/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0893 - val_loss: 4.7295\n",
            "Epoch 152/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1019 - val_loss: 4.7237\n",
            "Epoch 153/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1323 - val_loss: 4.7047\n",
            "Epoch 154/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.1110 - val_loss: 4.7575\n",
            "Epoch 155/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.0923 - val_loss: 4.7969\n",
            "Epoch 156/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.0807 - val_loss: 4.7643\n",
            "Epoch 157/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.0812 - val_loss: 4.7870\n",
            "Epoch 158/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.0692 - val_loss: 4.7723\n",
            "Epoch 159/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.0620 - val_loss: 4.7893\n",
            "Epoch 160/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.0558 - val_loss: 4.8242\n",
            "Epoch 161/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.0533 - val_loss: 4.8319\n",
            "Epoch 162/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.0528 - val_loss: 4.8000\n",
            "Epoch 163/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.0511 - val_loss: 4.8359\n",
            "Epoch 164/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.0495 - val_loss: 4.8278\n",
            "Epoch 165/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.0480 - val_loss: 4.8487\n",
            "Epoch 166/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.0468 - val_loss: 4.8519\n",
            "Epoch 167/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.0466 - val_loss: 4.8499\n",
            "Epoch 168/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.0467 - val_loss: 4.8544\n",
            "Epoch 169/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.0472 - val_loss: 4.8705\n",
            "Epoch 170/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.0461 - val_loss: 4.8739\n",
            "Epoch 171/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.0479 - val_loss: 4.8725\n",
            "Epoch 172/200\n",
            "2500/2500 [==============================] - 34s 14ms/step - loss: 0.0579 - val_loss: 4.8715\n",
            "Epoch 173/200\n",
            "2500/2500 [==============================] - 37s 15ms/step - loss: 0.0699 - val_loss: 4.9298\n",
            "Epoch 174/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0853 - val_loss: 4.8377\n",
            "Epoch 175/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.0867 - val_loss: 4.8279\n",
            "Epoch 176/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0807 - val_loss: 4.8523\n",
            "Epoch 177/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0684 - val_loss: 4.9242\n",
            "Epoch 178/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.0624 - val_loss: 4.8869\n",
            "Epoch 179/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0565 - val_loss: 4.9023\n",
            "Epoch 180/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0472 - val_loss: 4.9318\n",
            "Epoch 181/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0404 - val_loss: 4.9468\n",
            "Epoch 182/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0369 - val_loss: 4.9450\n",
            "Epoch 183/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0360 - val_loss: 4.9387\n",
            "Epoch 184/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0351 - val_loss: 4.9674\n",
            "Epoch 185/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0346 - val_loss: 4.9514\n",
            "Epoch 186/200\n",
            "2500/2500 [==============================] - 37s 15ms/step - loss: 0.0333 - val_loss: 4.9769\n",
            "Epoch 187/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0338 - val_loss: 4.9634\n",
            "Epoch 188/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0320 - val_loss: 4.9680\n",
            "Epoch 189/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0313 - val_loss: 5.0047\n",
            "Epoch 190/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0332 - val_loss: 4.9974\n",
            "Epoch 191/200\n",
            "2500/2500 [==============================] - 34s 13ms/step - loss: 0.0329 - val_loss: 4.9896\n",
            "Epoch 192/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0329 - val_loss: 4.9910\n",
            "Epoch 193/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0325 - val_loss: 4.9861\n",
            "Epoch 194/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0316 - val_loss: 5.0017\n",
            "Epoch 195/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0368 - val_loss: 4.9866\n",
            "Epoch 196/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0487 - val_loss: 5.0065\n",
            "Epoch 197/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0654 - val_loss: 4.9722\n",
            "Epoch 198/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0926 - val_loss: 5.0055\n",
            "Epoch 199/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0822 - val_loss: 4.9822\n",
            "Epoch 200/200\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0549 - val_loss: 4.9929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f36f97653c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9ALMG6VQ-gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        "\n",
        "def predict_sequence(model, tokenizer, source):\n",
        "\tprediction = model.predict(source, verbose=0)[0]\n",
        "\tintegers = [argmax(vector) for vector in prediction]\n",
        "\ttarget = list()\n",
        "\tfor i in integers:\n",
        "\t\tword = word_for_id(i, tokenizer)\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\ttarget.append(word)\n",
        "\treturn ' '.join(target)\n",
        "\n",
        "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
        "\tactual, predicted = list(), list()\n",
        "\tfor i, source in enumerate(sources):\n",
        "\t\tsource = source.reshape((1, source.shape[0]))\n",
        "\t\ttranslation = predict_sequence(model, hindi_tokenizer, source)\n",
        "\t\traw_src, raw_target = raw_dataset[i]\n",
        "\t\tif i < 30:\n",
        "\t\t\tprint('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
        "\t\tactual.append([raw_target.split()])\n",
        "\t\tpredicted.append(translation.split())\n",
        "\t# calculate BLEU score\n",
        "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\t# print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\t# print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\t# print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK6RdZm5Swxv",
        "colab_type": "code",
        "outputId": "521ad5d3-c91f-4f12-ffa8-dfcb2bda4f7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('train')\n",
        "evaluate_model(model, hindi_tokenizer, trainX, l[:train_length])\n",
        "# test on some test sequences\n",
        "print('test')\n",
        "evaluate_model(model, hindi_tokenizer, testX, l[train_length:])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "src=[help], target=[बचाओ], predicted=[बचाओ]\n",
            "src=[jump], target=[उछलो], predicted=[छलांग]\n",
            "src=[jump], target=[कूदो], predicted=[छलांग]\n",
            "src=[jump], target=[छलांग], predicted=[छलांग]\n",
            "src=[hello], target=[नमस्ते।], predicted=[नमस्ते।]\n",
            "src=[hello], target=[नमस्कार।], predicted=[नमस्ते।]\n",
            "src=[cheers], target=[वाहवाह], predicted=[वाहवाह]\n",
            "src=[cheers], target=[चियर्स], predicted=[वाहवाह]\n",
            "src=[got it], target=[समझे कि नहीं], predicted=[समझे कि नहीं]\n",
            "src=[im ok], target=[मैं ठीक हूँ।], predicted=[मैं ठीक हूँ।]\n",
            "src=[awesome], target=[बहुत बढ़िया], predicted=[बहुत बढ़िया]\n",
            "src=[come in], target=[अंदर आ जाओ।], predicted=[अंदर आ जाओ।]\n",
            "src=[get out], target=[बाहर निकल जाओ], predicted=[बाहर निकल जाओ]\n",
            "src=[go away], target=[चले जाओ], predicted=[चले जाओ]\n",
            "src=[goodbye], target=[ख़ुदा हाफ़िज़।], predicted=[ख़ुदा हाफ़िज़।]\n",
            "src=[perfect], target=[उत्तम], predicted=[उत्तम]\n",
            "src=[perfect], target=[सही], predicted=[उत्तम]\n",
            "src=[welcome], target=[आपका स्वागत है।], predicted=[आपका स्वागत है।]\n",
            "src=[welcome], target=[स्वागतम्।], predicted=[आपका स्वागत है।]\n",
            "src=[have fun], target=[मज़े करना।], predicted=[मज़े करना।]\n",
            "src=[have fun], target=[मौज करना।], predicted=[मज़े करना।]\n",
            "src=[have fun], target=[मज़े करो।], predicted=[मज़े करना।]\n",
            "src=[i forgot], target=[मैं भूल गया।], predicted=[मैं भूल गया।]\n",
            "src=[i forgot], target=[मैं भूल गई।], predicted=[मैं भूल गया।]\n",
            "src=[ill pay], target=[मैं पैसे दूंगा।], predicted=[मैं पैसे दूंगा।]\n",
            "src=[im fine], target=[मैं ठीक हूँ।], predicted=[मैं ठीक हूँ।]\n",
            "src=[im full], target=[मेरा पेट भर गया है।], predicted=[मेरा पेट भर गया है।]\n",
            "src=[lets go], target=[चलो चलें], predicted=[चलो चलें]\n",
            "src=[answer me], target=[मुझे जवाब दो।], predicted=[मुझे जवाब दो।]\n",
            "src=[birds fly], target=[पंछी उड़ते हैं।], predicted=[पंछी उड़ते हैं।]\n",
            "BLEU-1: 0.965040\n",
            "test\n",
            "src=[she cried out the moment she saw her mother], target=[उसने जैसे ही अपनी मम्मी को देखा वह चिल्ला उठी।], predicted=[उसको उसे मम्मी की में में से खुश हैं।]\n",
            "src=[she left the old newspapers lying in a heap], target=[उसने पुराने अखबारों को एक ढेर में करके छोड़ दिया।], predicted=[उसने अपने से से से से में में रोया।]\n",
            "src=[that movie theater always shows good movies], target=[उस सिनेमा हॉल में हमेशा अच्छी फ़िल्में लगतीं हैं।], predicted=[वह एक भाई एक जा होता चाहिए।]\n",
            "src=[the baby woke up in the middle of the night], target=[बच्चा की नींद आधी रात में खुल गई।], predicted=[कल कल कल कल कल बारिश पड़ेगी।]\n",
            "src=[the children tried to imitate their teacher], target=[बच्चों ने एकदूसरे की नकल करने की कोशिश करी।], predicted=[वे अपनी को को से शिक़ायत बोला।]\n",
            "src=[the government has been reforming education], target=[सरकार शिक्षा को सुधारने मे लगी हुई है।], predicted=[यह गाड़ी से हसीना लगती है।]\n",
            "src=[the male peacock has colorful tail feathers], target=[मोर की पूंछ के पंख रंगबिरंगी होते हैं।], predicted=[हमारी मौत को की सच्चाई समान ली]\n",
            "src=[the mother is leading her child by the hand], target=[माँ हाथ पकड़कर अपने बच्चे को ले जा रही है।], predicted=[कुछ लोगों के के को को को कुछ भी है।]\n",
            "src=[the thief cursed the police for finding him], target=[चोर ने पुलिस को उसको पकड़ने के लिए गाली दी।], predicted=[उसके सब में के लिए लिए खुश है।]\n",
            "src=[the world is changing more and more quickly], target=[दुनिया औरभीऔर तेज़ी से बदल रही है।], predicted=[यह एक भी पास पास आसान नहीं है।]\n",
            "src=[this coffee is so hot that i cant drink it], target=[यह कॉफ़ी इतनी गरम है कि मुझसे पी नहीं जा रही है।], predicted=[यह यह है यह यह बोलने लगती है।]\n",
            "src=[this is the very book that i wanted to read], target=[यह वही किताब है जिसे मैं पढ़ना चाह्ता था।], predicted=[यह लिए लिए के लिए किताब आसान है।]\n",
            "src=[waking up is the opposite of going to sleep], target=[जागना सोने का विलोम शब्द है।], predicted=[यहाँ पास बड़ा गाड़ियाँ हुआ]\n",
            "src=[whoever comes first will get the best seats], target=[जो भी पहले आएँगे उन्हें सबसे अच्छी सीटें मिलेंगीं।], predicted=[मेरी यहाँ से में में महीने रहता है।]\n",
            "src=[a big earthquake occurred in india yesterday], target=[भारत में कल एक बड़ा भूकम्प हुआ था।], predicted=[मुझे एक एक और में बार में सकता]\n",
            "src=[are you going to cut down all the trees here], target=[तुम यहाँ सारे के सारे पेड़ काट डालोगे क्या], predicted=[आप यहाँ से कितने खड़ी देख सकते हैं]\n",
            "src=[be sure to put out the fire before you leave], target=[जाने से पहले आग को भुजाना मत भूलना।], predicted=[अगर तो भी दवाई वह तो करने करने लिए था।]\n",
            "src=[because of his advice i was able to succeed], target=[मैं उसकी सलाह की वजह से कामयाब हो गया।], predicted=[मेरे मातापिता के स्टेशन बातें हैं।]\n",
            "src=[did it not occur to you to close the windows], target=[तुम्हें खिड़कियाँ बंद करने की नहीं सूझी], predicted=[वह लिए लिए क्या से कोई लेनादेना नहीं है।]\n",
            "src=[dont add sentences from copyrighted sources], target=[कॉपीराईट वाले सोत्रों से वाक्य न जोड़ें।], predicted=[वे की की से चिढ़ कमाता]\n",
            "src=[everyone could easily see his disappointment], target=[उसकी निराशा सभी आसानी से दिख सकते थे।], predicted=[वह तुम्हारे से से नहीं रहा है।]\n",
            "src=[he broke himself of the bad habit of smoking], target=[उसने अपनी सिगरेट पीने की बुरी आदत छोड़ दी।], predicted=[उसे उसे को को को से की हुए दिया।]\n",
            "src=[he is anxious to know the result of the test], target=[वह टेस्ट के नतीजे को जानने के लिए बेचैन है।], predicted=[वह उसका उसकी के लिए लिए खुश खुश था।]\n",
            "src=[he lost his balance and fell off his bicycle], target=[उसने अपना संतुलन खो दिया और वह अपनी साईकल पर से गिर गया।], predicted=[उसने अपने अपने अपने के साथ रोया।]\n",
            "src=[he ought to have made allowances for his age], target=[उसे अपनी उम्र के बारे में सोचना चाहिए था।], predicted=[हम इस में के में लिए बड़ा था।]\n",
            "src=[he tends to get angry when people oppose him], target=[जब लोग उसके खिलाफ़ जातें हैं तो वह गुस्सा हो जाता है।], predicted=[उसके उसके करने कोई लिए भी लगती है।]\n",
            "src=[he works on the farm from morning till night], target=[वह खेत पर सुबह से शाम तक काम करता है।], predicted=[वह कल रात और एक जल सपना था।]\n",
            "src=[his new book is going to come out next month], target=[उसकी नई किताब अगले महीने छपेगी।], predicted=[वह शायद से में एक महीने छोड़नी पड़ेगी।]\n",
            "src=[i am going to stay here for a couple of days], target=[मैं यहाँ एकदो दिन रहूँगा।], predicted=[मैं मैं से से से में रहना रहा हूँ।]\n",
            "src=[i have two sisters both of whom are married], target=[मेरी दो बहनें हैं और दोनो की शादी हो चुकी है।], predicted=[मेरा आदमी से समुंदर से देता हैं।]\n",
            "BLEU-1: 0.100706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-38M9jhZQNa",
        "colab_type": "code",
        "outputId": "73ed8a60-c4b3-408b-8e38-aea0190931cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install youtube_transcript_api"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading https://files.pythonhosted.org/packages/21/81/c4ae5534b113f4938b482f360babbbe6fda550441a4af8e1007dba518586/youtube_transcript_api-0.3.1-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from youtube_transcript_api) (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->youtube_transcript_api) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->youtube_transcript_api) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->youtube_transcript_api) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->youtube_transcript_api) (2.8)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRYbqXnFTog6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "id1='liJVSwOiiwg'\n",
        "id2='ghYIKh9F5VE'\n",
        "a=YouTubeTranscriptApi.get_transcript(id2,languages=['en'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy78ytrYZKsN",
        "colab_type": "code",
        "outputId": "378b7ec4-e140-4b7b-b84d-a3a37db4ddfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "transcript_list = YouTubeTranscriptApi.list_transcripts(idx)\n",
        "\n",
        "# iterate over all available transcripts\n",
        "for transcript in transcript_list:\n",
        "\n",
        "    # the Transcript object provides metadata properties\n",
        "    print(\n",
        "        transcript.video_id,\n",
        "        transcript.language,\n",
        "        transcript.language_code,\n",
        "        # whether it has been manually created or generated by YouTube\n",
        "        transcript.is_generated,\n",
        "        # whether this transcript can be translated or not\n",
        "        transcript.is_translatable,\n",
        "        # a list of languages the transcript can be translated to\n",
        "        transcript.translation_languages,\n",
        "    )\n",
        "\n",
        "    # fetch the actual transcript data\n",
        "    print(transcript.fetch())\n",
        "\n",
        "    # translating the transcript will return another transcript object\n",
        "    print(transcript.translate('en').fetch())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "liJVSwOiiwg English (auto-generated) en True True [{'language': 'Afrikaans', 'language_code': 'af'}, {'language': 'Albanian', 'language_code': 'sq'}, {'language': 'Amharic', 'language_code': 'am'}, {'language': 'Arabic', 'language_code': 'ar'}, {'language': 'Armenian', 'language_code': 'hy'}, {'language': 'Azerbaijani', 'language_code': 'az'}, {'language': 'Bangla', 'language_code': 'bn'}, {'language': 'Basque', 'language_code': 'eu'}, {'language': 'Belarusian', 'language_code': 'be'}, {'language': 'Bosnian', 'language_code': 'bs'}, {'language': 'Bulgarian', 'language_code': 'bg'}, {'language': 'Burmese', 'language_code': 'my'}, {'language': 'Catalan', 'language_code': 'ca'}, {'language': 'Cebuano', 'language_code': 'ceb'}, {'language': 'Chinese (Simplified)', 'language_code': 'zh-Hans'}, {'language': 'Chinese (Traditional)', 'language_code': 'zh-Hant'}, {'language': 'Corsican', 'language_code': 'co'}, {'language': 'Croatian', 'language_code': 'hr'}, {'language': 'Czech', 'language_code': 'cs'}, {'language': 'Danish', 'language_code': 'da'}, {'language': 'Dutch', 'language_code': 'nl'}, {'language': 'English', 'language_code': 'en'}, {'language': 'Esperanto', 'language_code': 'eo'}, {'language': 'Estonian', 'language_code': 'et'}, {'language': 'Filipino', 'language_code': 'fil'}, {'language': 'Finnish', 'language_code': 'fi'}, {'language': 'French', 'language_code': 'fr'}, {'language': 'Galician', 'language_code': 'gl'}, {'language': 'Georgian', 'language_code': 'ka'}, {'language': 'German', 'language_code': 'de'}, {'language': 'Greek', 'language_code': 'el'}, {'language': 'Gujarati', 'language_code': 'gu'}, {'language': 'Haitian Creole', 'language_code': 'ht'}, {'language': 'Hausa', 'language_code': 'ha'}, {'language': 'Hawaiian', 'language_code': 'haw'}, {'language': 'Hebrew', 'language_code': 'iw'}, {'language': 'Hindi', 'language_code': 'hi'}, {'language': 'Hmong', 'language_code': 'hmn'}, {'language': 'Hungarian', 'language_code': 'hu'}, {'language': 'Icelandic', 'language_code': 'is'}, {'language': 'Igbo', 'language_code': 'ig'}, {'language': 'Indonesian', 'language_code': 'id'}, {'language': 'Irish', 'language_code': 'ga'}, {'language': 'Italian', 'language_code': 'it'}, {'language': 'Japanese', 'language_code': 'ja'}, {'language': 'Javanese', 'language_code': 'jv'}, {'language': 'Kannada', 'language_code': 'kn'}, {'language': 'Kazakh', 'language_code': 'kk'}, {'language': 'Khmer', 'language_code': 'km'}, {'language': 'Kinyarwanda', 'language_code': 'rw'}, {'language': 'Korean', 'language_code': 'ko'}, {'language': 'Kurdish', 'language_code': 'ku'}, {'language': 'Kyrgyz', 'language_code': 'ky'}, {'language': 'Lao', 'language_code': 'lo'}, {'language': 'Latin', 'language_code': 'la'}, {'language': 'Latvian', 'language_code': 'lv'}, {'language': 'Lithuanian', 'language_code': 'lt'}, {'language': 'Luxembourgish', 'language_code': 'lb'}, {'language': 'Macedonian', 'language_code': 'mk'}, {'language': 'Malagasy', 'language_code': 'mg'}, {'language': 'Malay', 'language_code': 'ms'}, {'language': 'Malayalam', 'language_code': 'ml'}, {'language': 'Maltese', 'language_code': 'mt'}, {'language': 'Maori', 'language_code': 'mi'}, {'language': 'Marathi', 'language_code': 'mr'}, {'language': 'Mongolian', 'language_code': 'mn'}, {'language': 'Nepali', 'language_code': 'ne'}, {'language': 'Norwegian', 'language_code': 'no'}, {'language': 'Nyanja', 'language_code': 'ny'}, {'language': 'Odia', 'language_code': 'or'}, {'language': 'Pashto', 'language_code': 'ps'}, {'language': 'Persian', 'language_code': 'fa'}, {'language': 'Polish', 'language_code': 'pl'}, {'language': 'Portuguese', 'language_code': 'pt'}, {'language': 'Punjabi', 'language_code': 'pa'}, {'language': 'Romanian', 'language_code': 'ro'}, {'language': 'Russian', 'language_code': 'ru'}, {'language': 'Samoan', 'language_code': 'sm'}, {'language': 'Scottish Gaelic', 'language_code': 'gd'}, {'language': 'Serbian', 'language_code': 'sr'}, {'language': 'Shona', 'language_code': 'sn'}, {'language': 'Sindhi', 'language_code': 'sd'}, {'language': 'Sinhala', 'language_code': 'si'}, {'language': 'Slovak', 'language_code': 'sk'}, {'language': 'Slovenian', 'language_code': 'sl'}, {'language': 'Somali', 'language_code': 'so'}, {'language': 'Southern Sotho', 'language_code': 'st'}, {'language': 'Spanish', 'language_code': 'es'}, {'language': 'Sundanese', 'language_code': 'su'}, {'language': 'Swahili', 'language_code': 'sw'}, {'language': 'Swedish', 'language_code': 'sv'}, {'language': 'Tajik', 'language_code': 'tg'}, {'language': 'Tamil', 'language_code': 'ta'}, {'language': 'Tatar', 'language_code': 'tt'}, {'language': 'Telugu', 'language_code': 'te'}, {'language': 'Thai', 'language_code': 'th'}, {'language': 'Turkish', 'language_code': 'tr'}, {'language': 'Turkmen', 'language_code': 'tk'}, {'language': 'Ukrainian', 'language_code': 'uk'}, {'language': 'Urdu', 'language_code': 'ur'}, {'language': 'Uyghur', 'language_code': 'ug'}, {'language': 'Uzbek', 'language_code': 'uz'}, {'language': 'Vietnamese', 'language_code': 'vi'}, {'language': 'Welsh', 'language_code': 'cy'}, {'language': 'Western Frisian', 'language_code': 'fy'}, {'language': 'Xhosa', 'language_code': 'xh'}, {'language': 'Yiddish', 'language_code': 'yi'}, {'language': 'Yoruba', 'language_code': 'yo'}, {'language': 'Zulu', 'language_code': 'zu'}]\n",
            "[{'text': 'in this video I will show you how to', 'start': 0.03, 'duration': 6.869}, {'text': 'find YouTube video ID for any YouTube', 'start': 3.78, 'duration': 6.84}, {'text': 'video I will show you for desktop and', 'start': 6.899, 'duration': 7.231}, {'text': 'mobile thank you for watching and if you', 'start': 10.62, 'duration': 5.669}, {'text': 'liked this video then please like and', 'start': 14.13, 'duration': 6.3}, {'text': 'share this video first of all I will', 'start': 16.289, 'duration': 7.351}, {'text': 'show you how to find YouTube video ID', 'start': 20.43, 'duration': 7.08}, {'text': \"from computer so let's start open the\", 'start': 23.64, 'duration': 7.759}, {'text': 'YouTube video which you want to hit ID', 'start': 27.51, 'duration': 11.49}, {'text': 'now go to the video url you can find ID', 'start': 31.399, 'duration': 11.5}, {'text': 'after v equals this is YouTube video ID', 'start': 39.0, 'duration': 7.41}, {'text': 'for the video all YouTube videos contain', 'start': 42.899, 'duration': 6.901}, {'text': 'their ID in URL s your V equals sign and', 'start': 46.41, 'duration': 8.09}, {'text': \"it's mixed with number and alphabets\", 'start': 49.8, 'duration': 4.7}, {'text': '[Music]', 'start': 55.12, 'duration': 5.24}, {'text': 'now I will show you how to find YouTube', 'start': 57.12, 'duration': 7.92}, {'text': 'video ID in mobile device first open the', 'start': 60.36, 'duration': 7.56}, {'text': 'video and then find a Share Option on', 'start': 65.04, 'duration': 5.939}, {'text': 'video screen for that tab on video', 'start': 67.92, 'duration': 6.39}, {'text': 'screen once you tab you will find option', 'start': 70.979, 'duration': 6.031}, {'text': 'for share just have on it', 'start': 74.31, 'duration': 18.27}, {'text': '[Music]', 'start': 77.01, 'duration': 18.79}, {'text': 'now to have on copy link to copy video', 'start': 92.58, 'duration': 7.03}, {'text': 'URL and then paste it in notepad or any', 'start': 95.8, 'duration': 5.91}, {'text': 'text document', 'start': 99.61, 'duration': 15.669}, {'text': '[Music]', 'start': 101.71, 'duration': 13.569}, {'text': 'now you can see the video ID after dot B', 'start': 116.689, 'duration': 7.121}, {'text': 'when you copy the link from mobile then', 'start': 120.57, 'duration': 5.07}, {'text': 'you will get this kind of link', 'start': 123.81, 'duration': 5.25}, {'text': 'so after dot B has the video ID for that', 'start': 125.64, 'duration': 10.05}, {'text': 'video thank you for watching please', 'start': 129.06, 'duration': 9.239}, {'text': 'comment below if you have any question', 'start': 135.69, 'duration': 4.829}, {'text': 'or suggestion on how to find YouTube', 'start': 138.299, 'duration': 6.151}, {'text': 'video ID if you like this video please', 'start': 140.519, 'duration': 6.33}, {'text': 'give us thumbs up and share this video', 'start': 144.45, 'duration': 5.039}, {'text': \"if you don't subscribe our channel\", 'start': 146.849, 'duration': 5.401}, {'text': 'please subscribe to our channel to get', 'start': 149.489, 'duration': 5.33}, {'text': 'more updates', 'start': 152.25, 'duration': 2.569}]\n",
            "[{'text': 'in this video I will show you how to', 'start': 0.03, 'duration': 6.869}, {'text': 'find YouTube video ID for any YouTube', 'start': 3.78, 'duration': 6.84}, {'text': 'video I will show you for desktop and', 'start': 6.899, 'duration': 7.231}, {'text': 'mobile thank you for watching and if you', 'start': 10.62, 'duration': 5.669}, {'text': 'liked this video then please like and', 'start': 14.13, 'duration': 6.3}, {'text': 'share this video first of all I will', 'start': 16.289, 'duration': 7.351}, {'text': 'show you how to find YouTube video ID', 'start': 20.43, 'duration': 7.08}, {'text': \"from computer so let's start open the\", 'start': 23.64, 'duration': 7.759}, {'text': 'YouTube video which you want to hit ID', 'start': 27.51, 'duration': 11.49}, {'text': 'now go to the video url you can find ID', 'start': 31.399, 'duration': 11.5}, {'text': 'after v equals this is YouTube video ID', 'start': 39.0, 'duration': 7.41}, {'text': 'for the video all YouTube videos contain', 'start': 42.899, 'duration': 6.901}, {'text': 'their ID in URL s your V equals sign and', 'start': 46.41, 'duration': 8.09}, {'text': \"it's mixed with number and alphabets\", 'start': 49.8, 'duration': 4.7}, {'text': '[Music]', 'start': 55.12, 'duration': 5.24}, {'text': 'now I will show you how to find YouTube', 'start': 57.12, 'duration': 7.92}, {'text': 'video ID in mobile device first open the', 'start': 60.36, 'duration': 7.56}, {'text': 'video and then find a Share Option on', 'start': 65.04, 'duration': 5.939}, {'text': 'video screen for that tab on video', 'start': 67.92, 'duration': 6.39}, {'text': 'screen once you tab you will find option', 'start': 70.979, 'duration': 6.031}, {'text': 'for share just have on it', 'start': 74.31, 'duration': 18.27}, {'text': '[Music]', 'start': 77.01, 'duration': 18.79}, {'text': 'now to have on copy link to copy video', 'start': 92.58, 'duration': 7.03}, {'text': 'URL and then paste it in notepad or any', 'start': 95.8, 'duration': 5.91}, {'text': 'text document', 'start': 99.61, 'duration': 15.669}, {'text': '[Music]', 'start': 101.71, 'duration': 13.569}, {'text': 'now you can see the video ID after dot B', 'start': 116.689, 'duration': 7.121}, {'text': 'when you copy the link from mobile then', 'start': 120.57, 'duration': 5.07}, {'text': 'you will get this kind of link', 'start': 123.81, 'duration': 5.25}, {'text': 'so after dot B has the video ID for that', 'start': 125.64, 'duration': 10.05}, {'text': 'video thank you for watching please', 'start': 129.06, 'duration': 9.239}, {'text': 'comment below if you have any question', 'start': 135.69, 'duration': 4.829}, {'text': 'or suggestion on how to find YouTube', 'start': 138.299, 'duration': 6.151}, {'text': 'video ID if you like this video please', 'start': 140.519, 'duration': 6.33}, {'text': 'give us thumbs up and share this video', 'start': 144.45, 'duration': 5.039}, {'text': \"if you don't subscribe our channel\", 'start': 146.849, 'duration': 5.401}, {'text': 'please subscribe to our channel to get', 'start': 149.489, 'duration': 5.33}, {'text': 'more updates', 'start': 152.25, 'duration': 2.569}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAbwBhBLcHzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9715f350-c950-45b4-d839-99ab61280256"
      },
      "source": [
        "testy = []\n",
        "for i in a:\n",
        "    testy.append([i['text'],'Hindi target unkown'])\n",
        "testy[0]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Happy Thanksgiving', 'Hindi target unkown']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwjZuNrpdI2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testX = encode_sequences(eng_tokenizer, eng_length, np.array(testy)[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgKhATx-dTHj",
        "colab_type": "code",
        "outputId": "87972c4f-a40d-4fca-fe30-b88ea5f34a07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "evaluate_model(model, hindi_tokenizer, testX, testy)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src=[Happy Thanksgiving], target=[Hindi target unkown], predicted=[समझे हो]\n",
            "src=[thanks God will I'm so glad that you], target=[Hindi target unkown], predicted=[बाएं आपकी तुम्हारे तुम्हारे खुश कैफ़े]\n",
            "src=[came you just look great], target=[Hindi target unkown], predicted=[तुम किताब गया दिन आता]\n",
            "src=[mr. loss like 150 pounds yeah I'm gonna], target=[Hindi target unkown], predicted=[मुझे बस आ करते है।]\n",
            "src=[be one the Subway sandwich commercials], target=[Hindi target unkown], predicted=[मैं औरडर चला चला हूँ।]\n",
            "src=[okay alright alright snow fat no sugar], target=[Hindi target unkown], predicted=[मुझे जल्दी नहीं है।]\n",
            "src=[it's no dairy it's no good throw it out], target=[Hindi target unkown], predicted=[नहीं नहीं में नहीं नहीं करता।]\n",
            "src=[you're gonna meet some people says that], target=[Hindi target unkown], predicted=[इस उसकी हमारे सारे जो नहीं नहीं]\n",
            "src=[this is my husband Chandler Chandler], target=[Hindi target unkown], predicted=[यह मेरा पति है।]\n",
            "src=[this is will oh hey I'd shake your hand], target=[Hindi target unkown], predicted=[तुम्हारी है। है। है।]\n",
            "src=[but I'm really into the game plus I], target=[Hindi target unkown], predicted=[वे बहुत भाई सी सड़े भागता हैं।]\n",
            "src=[think it'd be better for my ego if we], target=[Hindi target unkown], predicted=[तुम्हे इसके करने में लिए नहीं नहीं रही]\n",
            "src=[didn't stand right next to each other], target=[Hindi target unkown], predicted=[यह थोड़ी खड़े या]\n",
            "src=[this is Phoebe hi hey], target=[Hindi target unkown], predicted=[यह हो रही]\n",
            "src=[well done I'm gonna give you a hand sure], target=[Hindi target unkown], predicted=[बिस्तर रातभर खड़े उतरेगा। था।]\n",
            "src=[Monica I can't get over how great you], target=[Hindi target unkown], predicted=[मैं तुमपर भरोसा कर हूँ। हूँ।]\n",
            "src=[look you look stunning], target=[Hindi target unkown], predicted=[तुम कब आऊँगा।]\n",
            "src=[oh you look incredible too you're just], target=[Hindi target unkown], predicted=[तुम यहाँ से नहीं चला था।]\n",
            "src=[you're so fit I'm watching the game but], target=[Hindi target unkown], predicted=[वे इनसान इनसान को को से से में होती होती है।]\n",
            "src=[I'm not deaf], target=[Hindi target unkown], predicted=[पंछी गाते]\n",
            "src=[meant to tell you a Ross is coming], target=[Hindi target unkown], predicted=[उसको वहाँ से से आ आ]\n",
            "src=[Ross's come great I love Ross good in], target=[Hindi target unkown], predicted=[मैं नौकरी की से दे किया हूँ।]\n",
            "src=[Rachel Green - OH], target=[Hindi target unkown], predicted=[अपने घोसले करो।]\n",
            "src=[their problem no uh it's okay it's just], target=[Hindi target unkown], predicted=[उसकी ने के से सहमत हैं।]\n",
            "src=[uh god I hated her], target=[Hindi target unkown], predicted=[मैंने उससे के काम की दे है।]\n",
            "src=[what yeah I hated her she was horrible], target=[Hindi target unkown], predicted=[वह लगता है है कोई मुझे नहीं नहीं]\n",
            "src=[to me in high school but hey it was a], target=[Hindi target unkown], predicted=[मैं इतनी का का में परिचित हूँ।]\n",
            "src=[long time ago I'm in a good place might], target=[Hindi target unkown], predicted=[रबड़ किसी से से से का का एक कौआ है।]\n",
            "src=[be actually fun to see her again], target=[Hindi target unkown], predicted=[उसके फिर से फिर से आई।]\n",
            "src=[gotta need cakes or cookies or something], target=[Hindi target unkown], predicted=[मेरे इस समय तीन समय सकता।]\n",
            "BLEU-1: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s90Xrj2AHnJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00ad016f-b549-49be-8d97-f2bf5e65b640"
      },
      "source": [
        "\n",
        "predict_sequence(model, hindi_tokenizer, testX[0].reshape((1, testX[2].shape[0])))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    }
  ]
}