from model import EnglishToHindi
from feature_extractor import FeatureExtractor

from youtube_transcript_api import YouTubeTranscriptApi


if __name__ == '__main__':

    id1='liJVSwOiiwg'
    id2='ghYIKh9F5VE'
    transcript=YouTubeTranscriptApi.get_transcript(id2,languages=['en'])

    transcript_list = YouTubeTranscriptApi.list_transcripts(id2)

    # iterate over all available transcripts
    for transcript in transcript_list:

        # the Transcript object provides metadata properties
        print(
            transcript.video_id,
            transcript.language,
            transcript.language_code,
            # whether it has been manually created or generated by YouTube
            transcript.is_generated,
            # whether this transcript can be translated or not
            transcript.is_translatable,
            # a list of languages the transcript can be translated to
            transcript.translation_languages,
        )

        # fetch the actual transcript data
        print(transcript.fetch())

        # translating the transcript will return another transcript object
        print(transcript.translate('en').fetch())

    
    fe = FeatureExtractor()
    train_length=2500
    model = EnglishToHindi('../data/hin.txt',train_length)
    model.fit(num_epochs=2)
    
    testy = []
    for i in transcript:
        testy.append([i['text'],'Hindi target unkown'])
    
    testX = fe.encode_sequences(model.eng_tokenizer, model.eng_length, np.array(testy)[:,0])
    (_,predicted)=evaluate_model(testX,testy)
    
    translation = ' '.join(predicted)
    
    file1 = open('eng_to_hindi_translated_script.srt',"w+")
    file1.write(translation)
    file1.close()
